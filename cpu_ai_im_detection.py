# -*- coding: utf-8 -*-
"""CPU_ai_im_detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/isramoussaoui/cpu-ai-im-detection.96126c25-8ad3-4285-9e24-cf0ad29976cb.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250427/auto/storage/goog4_request%26X-Goog-Date%3D20250427T083639Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D50e66391fad04d71d5a73893825fdd2473fae58986676d52d2b7b4332214f88d980ca4a602404f12929d154828509639d5216955df936f78f5ce5a6dcf58fa83b6b87034f0c949fde22218ad319ddd8c8fd53fc2f83452bfd5e18ee379458d683543b26ecee32dd465e372dc82bed54425126b21f99db68fa30bb8526ee2a83c555bf7dada5099a84ad54685309eb17aacc44526d8a25c67f6648368bf0c8c67ed784f9d258d9300f8beb5b22d6b555fd95b2a3f668ff82a85f80b4a7421d0e2ed2d6f1f04f2446ad98696574690a24e149febd4c32fa1e79bb8a722a15e08f65127a62e09999f4deaff03fcfb5f21696933c7421448d6a0766998ca5b934422
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
birdy654_cifake_real_and_ai_generated_synthetic_images_path = kagglehub.dataset_download('birdy654/cifake-real-and-ai-generated-synthetic-images')

print('Data source import complete.')

"""### For the first part of this challenge we will test a ViT model
## why this will work?
Vision Transformers can capture long-range dependencies in the image which is  helpful for detecting global inconsistencies like weird global texture drift that diffusion sometimes causes(if we consider that the majority of the ai generated models are generated via diffusion models but same can apply for GAN generated images)
"""

#our importss
import os
import PIL
import torch
from transformers import ViTForImageClassification
from transformers import ViTImageProcessor
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, transforms

#Preparing and loading the dataset
datapath="/kaggle/input/cifake-real-and-ai-generated-synthetic-images"
traindata=os.path.join(datapath,"train")
testdata=os.path.join(datapath,"test")

print("len of the training data for fake images ",len(os.listdir(os.path.join(traindata,"FAKE"))))
print("len of the training data for real images ",len(os.listdir(os.path.join(traindata,"REAL"))))
print("----------------------------------------")
print("len of the testing data for fake images ",len(os.listdir(os.path.join(testdata,"FAKE"))))
print("len of the testing data for real images ",len(os.listdir(os.path.join(testdata,"REAL"))))

#luckly for us the data is well organized so we are just gonna pass it to a data loader and pass it in the training loop

os.listdir(traindata)

import pathlib
data_dir=pathlib.Path(traindata)
data_dir

fakes=list(data_dir.glob('FAKE/*'))
reals=list(data_dir.glob('REAL/*'))
#just checking again
print(len(fakes),len(reals))

"""we will work with only 20 000 of the training images"""

PIL.Image.open(str(fakes[3]))

"""### the pretrained vit and processor"""

from transformers import AutoImageProcessor, AutoModelForImageClassification

processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")

#since we will be working with vit we have to apply the following
#trainsformations to the images before the model takes it
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)
])

import cv2
from PIL import Image
from torch.utils.data import Subset

!mkdir -p data/train/real
!mkdir -p data/train/fake
!mkdir -p data/test/real
!mkdir -p data/test/fake

train_dataset = datasets.ImageFolder(root=traindata, transform=transform)
subset_indices = torch.randperm(len(train_dataset))[:20000]
limited_train_dataset = Subset(train_dataset, subset_indices)

train_loader = DataLoader(limited_train_dataset, batch_size=32, shuffle=True)



print(len(train_loader)) #20000/32

#the testing dataset and dataloader
test_dataset = datasets.ImageFolder(root=testdata, transform=transform)
subset_indices = torch.randperm(len(test_dataset))[:5000]
limited_test_dataset = Subset(test_dataset, subset_indices)

test_loader = DataLoader(limited_test_dataset, batch_size=32, shuffle=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

"""### the model"""

model = ViTForImageClassification.from_pretrained(
    "google/vit-base-patch16-224-in21k",
    num_labels=2,#since we are working with real and fake
)

model.to(device)

import torch.nn as nn

loss_fn = nn.CrossEntropyLoss()
import torch.optim as optim

optimizer = optim.Adam(model.parameters(), lr=5e-5)
num_epochs = 3

for epoch in range(num_epochs):
    model.train()

    for index ,(images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)


        outputs = model(images)
        #print(outputs)
        logits = outputs.logits
        loss = loss_fn(logits, labels)
        if index%10==0:
            print(f"loss at {loss} at step :{index}")
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}")

print(model)

print(num_epochs)

model.eval()
correct = 0
total = 0
val_loss = 0

with torch.no_grad():
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)
        logits = outputs.logits
        loss = loss_fn(logits, labels)

        val_loss += loss.item()
        _, predicted = torch.max(logits, dim=1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

accuracy = correct / total
avg_loss = val_loss / len(test_loader)

print(f"Validation Accuracy: {accuracy:.4f}, Validation Loss: {avg_loss:.4f}")

torch.save(model.state_dict(), "isimage.pth")

testytestim="/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train/FAKE/1000 (3).jpg"
from PIL import Image
# Load your image
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

img = Image.open(testytestim).convert("RGB")

# Preprocess image using processor
inputs = processor(images=img, return_tensors="pt").to(device)
with torch.no_grad():
    outputs = model(**inputs)
    logits = outputs.logits
    predicted_class_idx = logits.argmax(-1).item()

print("Predicted class ID:", predicted_class_idx)
print("Predicted label:", model.config.id2label[predicted_class_idx])

#real 1
#fake 0

from transformers import ViTForImageClassification

model = ViTForImageClassification.from_pretrained("google/vit-base-patch16-224", num_labels=2,  ignore_mismatched_sizes=True)
model.load_state_dict(torch.load("isimage.pth"))
model.to(device)
model.eval()



